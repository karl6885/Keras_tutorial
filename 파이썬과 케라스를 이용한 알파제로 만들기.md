# 파이썬과 케라스를 이용한 알파제로 만들기 



> 원문: (Medium) [**How to build your own AlphaZero AI using Python and Keras**](https://medium.com/applied-data-science/how-to-build-your-own-alphazero-ai-using-python-and-keras-7f664945c188), David Foster
>
> 번역: 김영규
>
> *의역이 포함되어 원작자의 의도가 다르게 전해질 여지가 있으니 유의하시기 바랍니다. 만약 오역이나 오타를 발견하신다면 karl6885@gmail.com으로 메일 주시면 감사하겠습니다.*



[TOC]

부제: **컴퓨터가 자가 경기(self-play)와 딥러닝을 통해 Connect4 게임의 전략을 배울 수 있도록 가르쳐보자**



이 글에서는 3가지에 대해 다룰 것이다:



1. AlphaZero가 왜 인공지능으로 향하는 큰 발걸음인지에 대한 2가지 이유
2. AlphaZero 방법론을 따라한 모델을 만들어 Connect4라는 게임을 플레이하는 방법
3. 그 코드를 다른 게임에도 적용하는 방법





## AlphaGo -> AlphaGo Zero -> AlphaZero

2016년 3월, 2억 명이 지켜보는 가운데 DeepMind의 AlphaGo가 세계대회 18관왕의 바둑 선수 이세돌을 4-1로 이겼다. 기계가 인간을 능가하는 바둑 전략을 학습한 것이다. 이는 기존에 불가능하다고 생각되었던 것으로, 최소한 달성하려면 10년은 더 걸릴 것이라고 여기던 일이었다.

![Match 3 of AlphaGo vs Lee Sedol](https://cdn-images-1.medium.com/max/800/1*CKMFUcFNjS-owZEeBaBlhQ.png)

<div style="text-align: center;font-size:80%"> AlphaGo 대 이세돌 3번째 경기 </div>



이것은 그 자체로 엄청난 업적이었다. 그러나 2017년 10월 18일, DeepMind는 하나의 더 큰 도약을 이뤄낸다.



**'인간의 지식 없이 바둑을 마스터하기([Mastering the Game of Go without Human Knowledge](https://deepmind.com/research/publications/mastering-game-go-without-human-knowledge/))'** 라는 논문은 기존 알고리즘의 새로운 변형이자 AlphaGo를 100대 0으로 이긴 AlphaGo Zero를 소개한다. 놀랍게도 이것은 오직 자가대국을 통해 학습한 결과이며, 백지에서 시작해 점진적으로 자기 자신을 이기는 새로운 전략을 찾아가는 과정을 통해 이루어졌다. 인간을 능가하는 인공지능을 만드는 데 있어 더 이상 인간 전문가들의 대국 데이터베이스가 필요하지 않게 된 것이다.



![](https://cdn-images-1.medium.com/max/800/1*ROq9V2D5eR_dDFFFfjA5zw.png)

<div style="text-align: center;font-size:80%"> **‘인간의 지식 없이 바둑을 마스터하기(Mastering the Game of Go without Human Knowledge)'**  논문의 그래프</div>

그로부터 겨우 48일이 지난 2017년 12월 5일, DeepMind는 다른 논문  **'일반화된 강화학습 알고리즘을 활용한 자가 경기를 통해 체스와 쇼기 게임 마스터하기'([Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm](https://arxiv.org/pdf/1712.01815.pdf))**를 공개했다. 이 논문은 Alphago Zero를 체스와 Shogi 게임 각 분야에 적용하여 해당 분야 세계 최고의 프로그램인 StockFish와 Elmo를 이길 수 있음을 보였다. 이 모든 학습 과정에서, 컴퓨터 프로그램이 처음 게임을 마주한 순간부터 해당 분야의 세계 최고가 되기까지는 24시간이 채 걸리지 않았다.



인간 전문가의 전략에 대한 어떠한 사전 지식 없이도, 빠르게 어떤 분야를 잘 해낼 수 있는 일반화된 알고리즘인 AlphaZero는 이렇게 탄생했다.



## AlphaZero의 놀라운 2가지 점은 다음과 같다:



### *1. AlphaZero는 인간의 지식을 입력값으로 필요로 하지 않는다*

이 점이 얼마나 중요한지는 두말할 필요도 없다. 이것은 **어떤** 게임이든 간에 완전 정보적(플레이어들이 항상 게임의 상태를 파악할 수 있는)이기만 하면 AlphaGo Zero의 방법론을 적용할 수 있다는 것이다. 왜냐하면 게임의 규칙 외에는 어떤 선행 지식도 필요하지 않기 때문이다.

이것은 DeepMind가 AlphaGo Zero 논문을 낸 지 단 48일 만에 체스와 shogi 게임에 대한 논문을 새로 낼 수 있었던 배경이기도 하다. 말 그대로, 이를 위해 필요로 했던 것은 게임의 동작 원리를 설명하는 입력 파일을 바꾸는 것과 신경망/몬테 카를로 트리 서치(Monte Carlo Tree Search)와 관련된 하이퍼파라미터(Hyperparameter)를 수정하는 것이 전부였다.



### *2. 알고리즘이 놀라우리만큼 명쾌하다*

만일 AlphaZero가 고작 세계에서 몇 명 안 되는 사람들만 이해할 수 있는 매우 복잡한 알고리즘을 썼더라도, 그건 여전히 엄청난 기술이었을 것이다. 그러나 AlphaZero가 대단한 점은 논문 내에 있는 수많은 아이디어들이 그 이전 버전의 논문들보다 사실상 훨씬 덜 복잡하다는 것이다. 그리고 그 본질에는 학습에 대한 다음과 같은 아름다운 문장이 자리잡고 있다.



> 머릿속에서 가능한 미래 시나리오를 재생하고, 좋은 경로(path)에 대해 우선순위를 두면서, 다른 플레이어가 나의 ~



실제로 게임을 배우는 것과 비슷하게 들리지 않는가? 만약 잘못된 수를 두었다면, 이는 그 결과의 미래 가치를 잘못 계산했거나, 상대가 어떤 수를 둘 가능성을 잘못 판단해 그 가능성에 대해 생각해보지 않았기 때문일 것이다. 이것들이 바로 AlphaZero가 학습하는 게임의 두 가지 측면이다.



## 어떻게 AlphaZero를 만들 수 있을까

먼저, AlphaGo Zero가 어떻게 학습하는지 대략적으로 이해하기 위해 [AlphaGo Zero cheat sheet](https://medium.com/applied-data-science/alphago-zero-explained-in-one-diagram-365f5abf67e0)를 살펴보자. 코드의 각 파트를 살펴보면서 이것을 참조하면 좋으리라 생각된다. 추가적으로 AlphaZero가 어떻게 작동하는지 좀 더 자세히 설명하는 좋은 [글](http://tim.hibal.org/blog/alpha-zero-how-and-why-it-works/) 도 있다.



### 코드

여기서 설명하려는 코드는 [이 Github repository](https://github.com/AppliedDataSciencePartners/DeepReinforcementLearning)에 있으니 클론하자.

학습 과정(learning process)을 시작하려면, **run.ipynb** 라는 Jypyter notebook 파일의 상단에 있는 2개의 셀을 실행하면 된다. 메모리를 채울 정도로 충분한 경우의 수가 만들어지면 신경망이 학습을 시작한다. 추가적인 자가경기(self-play)와 학습을 통해, 신경망은 점진적으로 해당 게임의 가치와 어떤 위치에서의 다음 수를 잘 예측하게 된다. 그 결과 보다 나은 의사 결정과 전반적으로 보다 영리한 경기를 할 수 있게 된다.

이제 우리는 코드를 좀 더 자세히 들여다보고, 인공지능이 시간이 지남에 따라 강해지는 것을 보여주는 결과들을 살펴볼 것이다.

주의: 이것은 논문을 통해 얻은 정보를 바탕으로 AlphaZero가 어떻게 작동하는지를 나 스스로 이해한 것이다. 만약  아래 내용 중 뭔가 잘못되었다면, 죄송하고 그것을 고치기 위해 노력하겠다.



### Connect4

우리의 알고리즘이 학습하고자 하는 게임은 Connect4(혹은 Four In A Row라는 이름)이다. 바둑과 같이 복잡한 것은 아니지만.. 그럼에도 여전히 총 4,531,985,219,092개의 경우의 수가 존재한다.

![](https://cdn-images-1.medium.com/max/1600/1*3YJ_gww6ohN8EyupvSsC5g.png)

<div style="text-align: center;font-size:80%">Connect4</div>

![](https://upload.wikimedia.org/wikipedia/commons/a/ad/Connect_Four.gif)

<div style="text-align: center;font-size:80%">Connect4 하는 법. 이해를 돕기 위해 역자가 추가로 삽입하였습니다.</div>

이 게임의 룰은 간단하다. 플레이어들은 번갈아가며 자기의 색깔을 가진 돌을 각 열의 꼭대기에 넣는다. 먼저 가로, 세로, 또는 대각선으로 4개의 돌을 놓는다면 승리한다. 만약 모든 공간이 다 찼는데도 연속으로 4개의 돌이 놓이지 않았다면 그 게임은 무승부다.



여기 코드를 구성하는 핵심 파일들의 요약본이 있다:

### game.py

이 파일은 Connect4의 게임 규칙을 담고 있다.

각 정사각형(Square)들에는 다음과 같이 0부터 41까지의 번호가 할당되어 있다:

![](https://cdn-images-1.medium.com/max/1600/1*WEQi6kjP_tfiOC0zPF0I0g.png)

<div style="text-align: center;font-size:80%">Connect4의 Action squares </div>

game.py 파일은 